{
  "PLAYER_NAME": {
    "userlvl": "basic",
    "type": "string",
    "description": "Your current character name.",
    "_title": "Biography Management"
  },
  "DBDRIVER": {
    "userlvl": "wip",
    "type": "select",
    "values": [
      "postgresql"
    ],
    "description": "Do not change."
  },
  "LOCK_PROFILE": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "When enabled, this profile will be skipped when using 'Copy to All Profiles' functionality. It will also not be deleted when you Delete All Character Profiles. Can not be toggled for the default profile."
  },
  "HERIKA_NAME": {
    "userlvl": "basic",
    "type": "string",
    "description": "NPC Name. MUST MATCH their Skyrim in-game NPC name!<br>If you are in the default profile <b>YOU MUST</b> leave it as <i>The Narrator</i>!<br><b>You can change profiles by clicking the blue button in the top left.</b>"
  },
  "PROMPT_HEAD": {
    "userlvl": "pro",
    "type": "longstring",
    "description": "System Prompt. Defines the rules of the roleplay."
  },
  "PLAYER_BIOS": {
    "userlvl": "pro",
    "type": "longstring",
    "description": "Player character description. Any info here will be known by all AI NPC's."
  },
  "HERIKA_PERS": {
    "userlvl": "basic",
    "type": "longstring",
    "description": "1st half of NPC Bio. NPC Static Personality. <br> Should be core traits and facts about a person that does not change.<br>",
    "helpurl": "https://dwemerdynamics.hostwiki.io/en/Profiles"
  },
  "HERIKA_DYNAMIC": {
    "userlvl": "basic",
    "type": "longstring",
    "description": "2nd half of NPC Bio. NPC Dynamic Personality. <br> Should be feelings and traits about a person that can change based on ingame events. Use the settings below to update this automatically!<br><b>Do not worry if it is initially empty, as it will change when using dynamic profiles. </b>"
  },
  "dynamic_profile_b1": {
    "userlvl": "basic",
    "type": "util",
    "description": "This will update HERIKA_DYNAMIC, based on recent events. Can adjust the prompt used by editing DYNAMIC_PROMPT. Requires CONNECTOR_DIARY to be configured.",
    "action": "action_dynamic_profile_b1.php",
    "name": "Update Dynamic Profile"
  },
  "DYNAMIC_PROFILE": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Will automatically update HERIKA_DYNAMIC during certain ingame events (such as sleeping). Can adjust the prompt used by editing DYNAMIC_PROMPT. Requires CONNECTOR_DIARY to be configured."
  },
  "MINIME_T5": {
    "userlvl": "basic",
    "type": "boolean",
    "scope": "global",
    "description": "Enable Minime-T5 LLM. Helps dumber LLM's be more accurate with action and memory functions. Must be installed in the CHIM Launcher. <br> <strong> Must be configued in default profile and only works in English!</strong>"
  },
  "OGHMA_INFINIUM": {
    "type": "boolean",
    "userlvl": "basic",
    "description": "Needs Minime-T5 enabled and running. Tamriel lore information will be added to the prompt, enhancing their understanding on specific topics."
  },
  "OGHMA_KNOWLEDGE": {
    "type": "string",
    "userlvl": "basic",
    "description": "Knowledge Classes assigned to the NPC. Effects what articles they can access in the Oghma database. If you want to add more make sure they are comma separated. Recommend to leave as default.",
    "helpurl": "https://docs.google.com/spreadsheets/d/1dcfctU-iOqprwy2BOc7___4Awteczgdlv8886KalPsQ/edit?gid=338893641#gid=338893641"
  },
  "OGHMA_AMOUNT": {
    "type": "select",
    "values": [
      "1",
      "2",
      "3"
    ],
    "userlvl": "basic",
    "description": "Number of Oghma keywords to extract from each response. More keyword extraction will mean longer response times."
  },
  "RECHAT_H": {
    "userlvl": "basic",
    "type": "integer",
    "description": "Rechat Rounds. Higher values will increase the amount of times AI NPC's will go back-and-forth during a conversation.<br>1 = 1 Round | 2 = 2 Rounds | 3 = 3 Rounds etc",
    "_title": "Roleplay Management"
  },
  "RECHAT_P": {
    "userlvl": "basic",
    "type": "integer",
    "description": "Rechat Probability. Chance that an AI NPC will continue an ongoing conversation.<br>0 = Never | 50 = 50% | 100 = Always"
  },
  "RECHAT_ALLOW_ACTIONS": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Allow AI NPCs to trigger actions between eachother during Rechat. This can cause some chaos..."
  },
  "BORED_EVENT": {
    "userlvl": "basic",
    "type": "integer",
    "description": "Bored Event Probability. Chance of an AI NPC starting a random conversation every couple of minutes.<br>0 = Never | 50 = 50% | 100 = Always"
  },
  "BORED_EVENT_SERVERSIDE": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Smart Bored Events. Will use the director to generate dynamic bored event topics. It is slower but topics will improve the quality of bored event topics.",
    "scope": "global"
  },
  "CONTEXT_HISTORY": {
    "userlvl": "basic",
    "type": "integer",
    "description": "Amount of context history (dialogue and events) that will be sent to LLM. Improves short term memory.<br>Higher Context = more tokens used and slower response time.<br><b>We recommend you do not go over 100</b>"
  },
  "ALIVE_MESSAGE": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Whether the <i>I am alive..</i> response will trigger whenever you activate an AI NPC."
  },
  "TIME_AWARENESS": {
    "userlvl": "pro",
    "type": "boolean",
    "description": "Whether the NPC will be aware of how long it has been since you last talked to them, or if you are talking for the first time."
  },
  "BOOK_EVENT_FULL": {
    "userlvl": "pro",
    "type": "boolean",
    "description": "Send full contents of book instead of only the book title to the AI. This will consume more tokens, but the AI will accurately summarize any book or note!"
  },
  "BOOK_EVENT_ALWAYS_NARRATOR": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "The Narrator will be the only one to summarize books.<br><strong>SET THIS ON default profile to apply to all NPCs.</strong>",
    "scope": "global"
  },
  "NARRATOR_TALKS": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Enable the Narrator.",
    "scope": "global"
  },
  "NARRATOR_WELCOME": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "The Narrator will give you a quick recap of what happened previously after you have loaded a save game. Has a 10 minute IRL cooldown so its not annoying.",
    "scope": "global"
  },
  "QUEST_COMMENT": {
    "type": "boolean",
    "userlvl": "basic",
    "description": "Will trigger AI (NPCs and Narrator) to talk about new objectives in your current active quest. Will trigger a lot of events on a new character, so leave disabled until you complete the tutorial!"
  },
  "QUEST_COMMENT_CHANCE": {
    "type": "select",
    "userlvl": "basic",
    "values": [
      "10%",
      "25%",
      "50%",
      "75%",
      "100%"
    ],
    "description": "Chance that an AI Quest Comment will happen every time a quest updates."
  },
  "CURRENT_TASK": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Include the current Dynamic AI Objective to the AI NPC's prompt. Disable this if the AI NPC becomes fixated on the task."
  },
  "RPG_COMMENTS": {
    "type": "selectmultiple",
    "values": [
      "levelup",
      "learn_shout",
      "learn_word",
      "absorb_soul",
      "bleedout",
      "combat_end",
      "lockpick",
      "sleep",
      "keepmechecked"
    ],
    "description": "Pick which comments you want a chance to trigger when one of these ingame events happens."
  },
  "DETECT_MAGIC_EVENT": {
    "userlvl": "basic",
    "type": "boolean",
    "scope": "global",
    "description": "Enable detection and logging of spellcasting events. When disabled, spellcast events will not be logged to the context log."
  },
  "MAGIC_EVENT_BLACKLIST": {
    "userlvl": "basic",
    "type": "longstring",
    "scope": "global",
    "description": "Comma-separated list of magic event names to exclude from logging (e.g. 'Administer Mixture, [BFCO-AttackSwingFX] 0.5/1.5, Healing')."
  },
  "HERIKA_ANIMATIONS": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Will issue animations for the NPC to play",
    "helpurl": "https://dwemerdynamics.hostwiki.io/en/Advanced-Features",
    "_title": "Advanced Configuration"
  },
  "CORE_LANG": {
    "userlvl": "pro",
    "type": "select",
    "description": "Custom Language. The lang folder is in the CHIM Server. Leave it blank for English."
  },
  "LANG_LLM_XTTS": {
    "userlvl": "pro",
    "type": "boolean",
    "description": "XTTS Only! Will offer a language field to LLM, and will try match to XTTSv2 language."
  },
  "HTTP_TIMEOUT": {
    "userlvl": "pro",
    "type": "integer",
    "description": "Timeout for AI requests. "
  },
  "MAX_WORDS_LIMIT": {
    "userlvl": "basic",
    "type": "integer",
    "description": "Enforce a word limit for AI's responses. Leave as 0 to have no limit."
  },
  "JSON_DIALOGUE_FORMAT_REORDER": {
    "type": "boolean",
    "userlvl": "pro",
    "description": "Reorders properties in the output JSON schema. AI generates an action first, then a dialogue comment. Some users report this improves actions performance."
  },
  "EMOTEMOODS": {
    "userlvl": "pro",
    "type": "longstring",
    "description": "List of moods passed to LLM (comma separated). Some of them will trigger appropriate animations if animations are enabled",
    "helpurl": "https://dwemerdynamics.hostwiki.io/en/Advanced-Features"
  },
  "REMOVE_ASTERISKS_FROM_OUTPUT": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Remove text between **, like *couch*, *smiles*...",
    "helpurl": "https://dwemerdynamics.hostwiki.io/en/Advanced-Features"
  },
  "ENFORCE_ACTIONS_PROMPT": {
    "userlvl": "basic",
    "type": "boolean",
    "description": "Adds a prompt to enforce use of actions",
    "helpurl": ""
  },
  "SUMMARY_PROMPT": {
    "userlvl": "pro",
    "type": "longstring",
    "description": "Default profile only! Custom instructions added when generating summaries for memories. You can adjust max tokens by changing MAX_TOKENS_MEMORY for the SUMMARY connector you are using.",
    "scope": "global"
  },
  "DYNAMIC_PROMPT": {
    "userlvl": "basic",
    "type": "longstring",
    "description": "Default profile only! Instructions for updating HERIKA_DYNAMIC. You can adjust max tokens by changing MAX_TOKENS_MEMORY for the SUMMARY connector you are using.",
    "scope": "global"
  },
  "CONNECTORS": {
    "type": "selectmultiple",
    "values": [
      "openrouterjson",
      "openrouter",
      "openrouterjsonanthropic",
      "openrouteranthropic",
      "openaijson",
      "openai",
      "google_openaijson",
      "web_connector",
      "koboldcppjson",
      "koboldcpp"
    ],
    "description": "AI Service(s) to be used for most AI features.<br>Select the service(s) you have configured for AI/LLM Connectors below.<br><strong>Non JSON connectors are legacy and no longer supported. We can not debug or fix any issues you have with them!</strong><br><br>Make sure to click the <strong>Current AI Service</strong> button at the top of the page if you change connectors!",
    "_title": "AI/LLM Connectors Selection"
  },
  "CONNECTORS_DIARY": {
    "type": "select",
    "values": [
      "openrouter",
      "openrouteranthropic",
      "openai",
      "google_openaijson",
      "koboldcpp"
    ],
    "description": "Is one of the SUMMARY connectors. Used for creating diary entries, dynamic profiles and summarized memories!<br><br><strong>You will need to place your API key in the (SUMMARY) connector for this to work!</strong>"
  },
  "CONNECTOR": {
    "_title": "AI/LLM Connectors",
    "openrouterjson": {
      "_title": "OpenRouter API (JSON)",
      "url": {
        "type": "url",
        "description": "OpenRouter API endpoint"
      },
      "model": {
        "type": "ormodellist",
        "description": "<strong>Must be JSON/Instruct type of Model!</strong><br>FREE MODELS ARE NOT RECOMMENDED!<br>If you change model use buttons below to set new parameters!",
        "helpurl": "https://openrouter.ai/docs#models"
      },
      "PROVIDER": {
        "type": "string",
        "description": "Leave blank unless you want to manually select a provider from OpenRouter. It is case sensitive!",
        "helpurl": "https://openrouter.ai/docs/provider-routing"
      },
      "reasoning_model": {
        "type": "boolean",
        "description": "This is a reasoning model, could output <strong>CoT</strong>.",
        "helpurl": "https://openrouter.ai/docs/use-cases/reasoning-tokens"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate."
      },
      "get_parms1": {
        "type": "util",
        "userlvl": "wip",
        "description": "Autofill parameter settings for the currently selected model for minimal randomness in AI response (P10)",
        "action": "action_openrouterjson_get_parm_p1.php?P=10",
        "name": "Autofill Parameters: Low Randomness",
        "helpurl": "https://openrouter.ai/docs/parameters"
      },
      "get_parms5": {
        "type": "util",
        "userlvl": "wip",
        "description": "Autofill parameter settings for the currently selected model for some randomness in AI response (P50)",
        "action": "action_openrouterjson_get_parm_p1.php?P=50",
        "name": "Autofill Parameters: Medium Randomness",
        "helpurl": "https://openrouter.ai/docs/parameters"
      },
      "get_parms9": {
        "type": "util",
        "userlvl": "wip",
        "description": "Autofill parameter settings for the currently selected model for high randomness in AI response (P90)",
        "action": "action_openrouterjson_get_parm_p1.php?P=90",
        "name": "Autofill Parameters: High Randomness",
        "helpurl": "https://openrouter.ai/docs/parameters"
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "presence_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Presence Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "frequency_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Frequency Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "repetition_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Repetition Penalty [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_k": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_K [0-100]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "min_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Min_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_a": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_A [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "ENFORCE_JSON": {
        "type": "boolean",
        "description": "Will attempt to enforce dumb LLM's to stay in JSON format. Leave as default (TRUE), only works with specific models.",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "PREFILL_JSON": {
        "type": "boolean",
        "description": "Will attempt to prefill the JSON AI response for some dumber LLM's. Leave as default (FALSE), only works with specific models.",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "MAX_TOKENS_MEMORY": {
        "userlvl": "wip",
        "type": "wip",
        "description": "No longer used. Use SUMMARY connector for memory tokens instead."
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenRouter key",
        "code": "OPENAI_API_KEY"
      },
      "xreferer": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "xtitle": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "json_schema": {
        "type": "boolean",
        "description": "Enable OpenRouter Json schema. Does not work with all models. You must set a provider that supports structured outputs. Requires ENFORCE_JSON to be true.",
        "helpurl": "https://openrouter.ai/docs/structured-outputs#model-support"
      }
    },
    "openrouter": {
      "_title": "OpenRouter API (SUMMARY)",
      "url": {
        "type": "url",
        "description": "OpenRouter API endpoint"
      },
      "model": {
        "type": "ormodellist",
        "description": "Model to use.<br>FREE MODELS ARE NOT RECOMMENDED!<br>If you change model use buttons below to set new parameters!",
        "helpurl": "https://openrouter.ai/docs#models"
      },
      "PROVIDER": {
        "type": "string",
        "description": "Leave blank unless you want to manually select a provider from OpenRouter. It is case sensitive!",
        "helpurl": "https://openrouter.ai/docs/provider-routing"
      },
      "reasoning_model": {
        "type": "boolean",
        "description": "This is a reasoning model, could output <strong>CoT</strong>.",
        "helpurl": "https://openrouter.ai/docs/use-cases/reasoning-tokens"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate for regular responses, NOT SUMMARIES."
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "presence_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Presence Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "frequency_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Frequency Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "repetition_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Repetition Penalty [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_k": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_K [0-100]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "min_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Min_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_a": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_A [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenRouter key",
        "code": "OPENAI_API_KEY"
      },
      "MAX_TOKENS_MEMORY": {
        "type": "integer",
        "description": "Maximum tokens to generate when summarizing, diary entries, and dynamic profile updates."
      },
      "xreferer": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "xtitle": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "get_parms1": {
        "type": "util",
        "userlvl": "wip",
        "description": "Autofill parameter settings for the currently selected model for minimal randomness in AI response (P10)",
        "action": "action_openrouter_get_parm_p1.php?P=10",
        "name": "Autofill Parameters: Low Randomness",
        "helpurl": "https://openrouter.ai/docs/parameters"
      },
      "get_parms5": {
        "type": "util",
        "userlvl": "wip",
        "description": "Autofill parameter settings for the currently selected model for some randomness in AI response (P50)",
        "action": "action_openrouter_get_parm_p1.php?P=50",
        "name": "Autofill Parameters: Medium Randomness",
        "helpurl": "https://openrouter.ai/docs/parameters"
      },
      "get_parms9": {
        "type": "util",
        "userlvl": "wip",
        "description": "Autofill parameter settings for the currently selected model for high randomness in AI response (P90)",
        "action": "action_openrouter_get_parm_p1.php?P=90",
        "name": "Autofill Parameters: High Randomness",
        "helpurl": "https://openrouter.ai/docs/parameters"
      }
    },
    "openrouterjsonanthropic": {
      "_title": "OpenRouter Caching API for Anthropic (JSON)",
      "url": {
        "type": "url",
        "description": "OpenRouter API endpoint for Anthropic models"
      },
      "model": {
        "type": "ormodellist",
        "description": "<strong>Must be JSON/Instruct type of Model!</strong><br>FREE MODELS ARE NOT RECOMMENDED!<br>If you change model use buttons below to set new parameters! !!! DO NOT use models other than Antrhopic models",
        "helpurl": "https://openrouter.ai/docs#models"
      },
      "PROVIDER": {
        "type": "string",
        "description": "Leave blank unless you want to manually select a provider from OpenRouter. It is case sensitive!",
        "helpurl": "https://openrouter.ai/docs/provider-routing"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate."
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "presence_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Presence Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "frequency_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Frequency Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "repetition_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Repetition Penalty [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_k": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_K [0-100]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "min_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Min_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_a": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_A [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "ENFORCE_JSON": {
        "type": "boolean",
        "description": "Will attempt to enforce dumb LLM's to stay in JSON format. Leave as default (TRUE), only works with specific models.",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "PREFILL_JSON": {
        "type": "boolean",
        "description": "Will attempt to prefill the JSON AI response for some dumber LLM's. Leave as default (FALSE), only works with specific models.",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenRouter key",
        "code": "OPENAI_API_KEY"
      },
      "xreferer": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "xtitle": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "json_schema": {
        "type": "boolean",
        "description": "Enable OpenRouter Json schema. Does not work with all models. You must set a provider that supports structured outputs. Requires ENFORCE_JSON to be true.",
        "helpurl": "https://openrouter.ai/docs/structured-outputs#model-support"
      },
      "gemini_toggle": {
        "type": "boolean",
        "userlvl": "wip",
        "description": "Set this to true if using Gemini. Gemini needs a different form of caching."
      },
      "max_dialogue_cache_context_size": {
        "_title": "Maximum Event Cache Size",
        "userlvl": "pro",
        "type": "number",
        "description": "Controls how big the cached context size can get until it resets. Default value is 4 times CONTEXT_HISTORY."
      },
      "custom_last_instruction": {
        "type": "longstring",
        "userlvl": "wip",
        "description": "Leave blank unless you want to add something to the last part of the system prompt."
      },
      "custom_last_user_instruction": {
        "type": "longstring",
        "userlvl": "wip",
        "description": "Leave blank unless you want to add something to the last part of the user prompt."
      },
      "toggle_thinking": {
        "type": "boolean",
        "userlvl": "wip",
        "description": "Toggle caching on or off. Only works on supporting models."
      },
      "thinking_tokens": {
        "type": "number",
        "userlvl": "wip",
        "description": "How many maximum thinking tokens should be used. Must be higher the output token."
      }
    },
    "openrouteranthropic": {
      "_title": "OpenRouter Caching API for Anthropic (SUMMARY)",
      "url": {
        "type": "url",
        "description": "OpenRouter API endpoint for Anthropic models"
      },
      "model": {
        "type": "ormodellist",
        "description": "Model to use.<br>FREE MODELS ARE NOT RECOMMENDED!<br>If you change model use buttons below to set new parameters!",
        "helpurl": "https://openrouter.ai/docs#models"
      },
      "PROVIDER": {
        "type": "string",
        "description": "Leave blank unless you want to manually select a provider from OpenRouter. It is case sensitive!",
        "helpurl": "https://openrouter.ai/docs/provider-routing"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate for regular responses, NOT SUMMARIES."
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "presence_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Presence Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "frequency_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Frequency Penalty [(-2)-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "repetition_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Repetition Penalty [0-2]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_k": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_K [0-100]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "min_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Min_P [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "top_a": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_A [0-1]",
        "helpurl": "https://openrouter.ai/docs#format"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenRouter key",
        "code": "OPENAI_API_KEY"
      },
      "MAX_TOKENS_MEMORY": {
        "type": "integer",
        "description": "Maximum tokens to generate when summarizing, diary entries, and dynamic profile updates."
      },
      "xreferer": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "xtitle": {
        "userlvl": "wip",
        "type": "string",
        "description": "Stub needed header. Keep default."
      },
      "system_cache_strategy": {
        "_title": "Caching Options",
        "userlvl": "pro",
        "type": "select",
        "values": [
          "content",
          "ttl"
        ],
        "description": "Controls how the '<i>local system cache</i>' is updated.<br>Each NPC profile has its own separate <i>local system cache</i>.<br><br><b>content:</b><br><code>Always checks if the <i>local system cache</i> changed before sending to Anthropic (most up-to-date, more frequent cache rewrites, potentially higher costs).</code><br><b>ttl:</b><br><code>Reuses the saved <i>local system cache</i> for a set time (potentially stale information, less frequent cache rewrites, potentially lower costs). <i>Recommended</i>.</code><br><br>The <i>local system cache</i> (depending on your settings/mods) potentially includes all of the following:<br>- <code>PROMPT_HEAD, PLAYER_BIOS, HERIKA_PERS, HERIKA_DYNAMIC</code><br>- <code>Player/NPC Disposition</code><br>- <code>Player/NPC Appearance/Cleanliness</code><br>- <code>Location (Indoors/Outdoors)</code><br>- <code>Weather</code>"
      },
      "system_cache_ttl": {
        "userlvl": "pro",
        "type": "integer",
        "description": "<b>If strategy is 'ttl'</b>, this sets how long (in seconds) to reuse the <i>local</i> copy of the system cache before checking for updates (TTL = 'Time to Live').<br><b>Example:</b> 900 = 15 mins, 1800 = 30 mins. <i>Default: 900</i>.<br>0 = Check every time &amp; force rebuild. <b><i>Strongly Disadvised!</i></b> Adds overhead and likely increases costs.<br><br><b>Note:</b><br> <code>If using strategy <b>'ttl'</b>, it is recommended to set this value the same as the 'Dialogue Cache TTL' to minimize how often the combined cache needs rewriting.</code><br><b>Important:</b><br> <code>This <i>only</i> applies if strategy is <b>'ttl'</b> and controls the <i>local</i> copy only. Anthropic's own server cache expires after <i>5 minutes of not talking to this specific NPC</i>, regardless of this local setting.</code><br><br><br><br>"
      },
      "dialogue_cache_ttl": {
        "userlvl": "pro",
        "type": "integer",
        "description": "How long (in seconds) to reuse <i>local</i> saved chunks of this NPC's conversation history (TTL = 'Time to Live').<br><b>Example:</b> 900 = 15 mins, 1800 = 30 mins. <i>Default: 900</i>.<br>0 = Disable cache reuse. <b><i>Strongly Disadvised!</i></b> Forces inefficient rebuilds on every request, increasing overhead &amp; costs.<br><br><b>Note:</b><br> <code>If using System Cache strategy <b>'ttl'</b>, it is recommended to set this value the same as the 'System Cache TTL' to minimize how often the combined cache needs rewriting.</code><br><b>Important:</b><br> <code>This controls the <i>local</i> copy only. Anthropic's own server cache expires after <i>5 minutes of not talking to this specific NPC</i>, regardless of this local setting.</code>"
      },
      "dialogue_cache_uncached_count": {
        "userlvl": "pro",
        "type": "integer",
        "description": "How many <i>recent</i> conversation turns (Your message + NPC reply = 2 turns) to <i>always</i> exclude from the <i>local</i> saved dialogue chunk <i>during cache rebuilds</i>, minus 1 for final system prompt. <i><b>Do not set to 0</b></i>.<br><b>Example:</b> 5 = Keep last 4 turns fully dynamic during rebuilds.<br>1 = Save as much history as possible in the cache during rebuilds. <i>Default: 5</i>.<br><br><b>Note:</b><br> <code>When the local dialogue cache <i>is valid</i> (within its TTL), messages sent <i>after</i> the saved chunk are added individually. This means the amount of <code>'recent context after cache write'</code> grows with each turn in the conversation until the dialogue cache expires and gets rebuilt based on this setting.</code><br>"
      },
      "toggle_thinking": {
        "type": "boolean",
        "userlvl": "wip",
        "description": "Toggle caching on or off. Only works on supporting models."
      },
      "thinking_tokens": {
        "type": "number",
        "userlvl": "wip",
        "description": "How many maximum thinking tokens should be used. Must be higher the output token."
      }
    },
    "openaijson": {
      "_title": "OpenAI/ChatGPT API (JSON)",
      "url": {
        "type": "url",
        "description": "OpenAI API endpoint"
      },
      "model": {
        "type": "string",
        "description": "Model to use",
        "helpurl": "https://platform.openai.com/docs/models/"
      },
      "reasoning_model": {
        "type": "boolean",
        "description": "This is a reasoning model, could output <strong>CoT</strong>.",
        "helpurl": "https://platform.openai.com/docs/guides/reasoning?api-mode=responses"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate"
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "presence_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Presence Penalty [(-2)-2]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "frequency_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Frequency Penalty [(-2)-2]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenAI API key",
        "code": "OPENAI_API_KEY",
        "helpurl": "https://platform.openai.com/account/api-keys"
      },
      "MAX_TOKENS_MEMORY": {
        "userlvl": "wip",
        "type": "integer",
        "description": "No longer used. Use SUMMARY connector for memory tokens instead."
      },
      "json_schema": {
        "type": "boolean",
        "description": "Enable OpenAI Json schema. Does not work with all OpenAI's models",
        "helpurl": "https://platform.openai.com/docs/guides/structured-outputs?lang=js"
      }
    },
    "openai": {
      "_title": "OpenAI/ChatGPT API (SUMMARY)",
      "url": {
        "type": "url",
        "description": "OpenAI API endpoint"
      },
      "model": {
        "type": "string",
        "description": "Model to use",
        "helpurl": "https://platform.openai.com/docs/models/"
      },
      "reasoning_model": {
        "type": "boolean",
        "description": "This is a reasoning model, could output <strong>CoT</strong>.",
        "helpurl": "https://platform.openai.com/docs/guides/reasoning?api-mode=responses"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate for regular responses, NOT SUMMARIES."
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "presence_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Presence Penalty [(-2)-2]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "frequency_penalty": {
        "userlvl": "pro",
        "type": "number",
        "description": "Frequency Penalty [(-2)-2]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://platform.openai.com/docs/api-reference/completions/create"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenAI API key",
        "code": "OPENAI_API_KEY",
        "helpurl": "https://platform.openai.com/account/api-keys"
      },
      "MAX_TOKENS_MEMORY": {
        "type": "integer",
        "description": "Maximum tokens to generate when summarizing, diary entries, and dynamic profile updates."
      }
    },
    "google_openaijson": {
      "_title": "Google OpenAI API (JSON/SUMMARY)",
      "url": {
        "type": "url",
        "description": "Google OpenAI API endpoint"
      },
      "model": {
        "type": "string",
        "description": "Model to use",
        "helpurl": "https://ai.google.dev/gemini-api/docs/models/gemini"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate"
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]",
        "helpurl": "https://ai.google.dev/api/generate-content#generationconfig"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]",
        "helpurl": "https://ai.google.dev/api/generate-content#generationconfig"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "Google API key",
        "code": "OPENAI_API_KEY",
        "helpurl": "https://aistudio.google.com/apikey"
      },
      "MAX_TOKENS_MEMORY": {
        "type": "integer",
        "description": "Maximum tokens to generate when summarizing, diary entries, and dynamic profile updates."
      },
      "json_schema": {
        "type": "boolean",
        "description": "Enable OpenAI Json schema.",
        "helpurl": "https://platform.openai.com/docs/guides/structured-outputs?lang=js"
      }
    },
    "web_connector": {
      "_title": "Websocket Connector"
    },
    "koboldcppjson": {
      "_title": "KoboldCPP API (JSON)",
      "url": {
        "type": "url",
        "description": "Kobold should be running on the same machine as DwemerDistro!<br>Must use your computers, not the DwemerDistro, IP Address.<br>Can be found by running the command 'ipconfig' in your CMD prompt.<br>Example: http://your-local-ip:8008",
        "helpurl": "https://dwemerdynamics.hostwiki.io/en/Offline-LLMs"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate"
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]"
      },
      "rep_pen": {
        "type": "number",
        "description": "Repetition Penalty [0-2]"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]"
      },
      "min_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Min_P [0-1]"
      },
      "top_k": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_K [0-100]"
      },
      "PREFILL_JSON": {
        "type": "boolean",
        "description": "Will prefill JSON, which is useful for some AI models, and destroy others."
      },
      "MAX_TOKENS_MEMORY": {
        "userlvl": "wip",
        "type": "integer",
        "description": "No longer used. Use SUMMARY connector for memory tokens instead."
      },
      "newline_as_stopseq": {
        "type": "boolean",
        "description": "A new line in the output that will be considered a stop sequence. Recommended to leave as default."
      },
      "use_default_badwordsids": {
        "type": "boolean",
        "description": "Unban End of Sentence (EOS) tokens. If set to false the LLM will stop generating when it detects an EOS token."
      },
      "eos_token": {
        "type": "string",
        "description": "EOS token LLM uses. Only works if use_default_badwordsids is enabled."
      },
      "template": {
        "type": "select",
        "values": [
          "vicuna-1",
          "vicuna-1.1",
          "alpaca",
          "synthia",
          "extended-alpaca",
          "superHOT",
          "chatml",
          "chatml-c",
          "zephyr",
          "openchat",
          "dreamgen",
          "neuralchat",
          "phi",
          "llama3",
          "gromenauer",
          "gemma2",
          "alpacajson",
          "mistral-ins"
        ],
        "description": "Prompt Format. Specified in the HuggingFace model card"
      },
      "grammar": {
        "type": "boolean",
        "description": "Enforces use of JSON grammar. True to enforce (generation speed loss, but json format guaranteed). if false, the generation speed will be better but will depend on the model to produce valid JSON output."
      }
    },
    "koboldcpp": {
      "_title": "KoboldCPP API (SUMMARY)",
      "url": {
        "type": "url",
        "description": "Kobold should be running on the same machine as DwemerDistro!<br>Must use your computers, not the DwemerDistro, IP Address.<br>Can be found by running the command 'ipconfig' in your CMD prompt.<br>Example: http://your-local-ip:8008",
        "helpurl": "https://dwemerdynamics.hostwiki.io/en/Offline-LLMs"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate for regular responses, NOT SUMMARIES."
      },
      "temperature": {
        "type": "number",
        "description": "Temperature [0-2]"
      },
      "rep_pen": {
        "userlvl": "pro",
        "type": "number",
        "description": "Repetition Penalty [0-2]"
      },
      "top_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_P [0-1]"
      },
      "min_p": {
        "userlvl": "pro",
        "type": "number",
        "description": "Min_P [0-1]"
      },
      "top_k": {
        "userlvl": "pro",
        "type": "number",
        "description": "Top_K [0-100]"
      },
      "MAX_TOKENS_MEMORY": {
        "type": "integer",
        "description": "Maximum tokens to generate when summarizing, diary entries, and dynamic profile updates."
      },
      "newline_as_stopseq": {
        "type": "boolean",
        "description": "A new line in the output that will be considered a stop sequence. Recommended to leave as default."
      },
      "use_default_badwordsids": {
        "type": "boolean",
        "description": "Unban End of Sentence (EOS) tokens. If set to false the LLM will stop generating when it detects an EOS token."
      },
      "eos_token": {
        "type": "string",
        "description": "EOS token LLM uses. Only works if use_default_badwordsids is enabled."
      },
      "template": {
        "type": "select",
        "values": [
          "vicuna-1",
          "vicuna-1.1",
          "alpaca",
          "synthia",
          "extended-alpaca",
          "superHOT",
          "chatml",
          "chatml-c",
          "zephyr",
          "openchat",
          "dreamgen",
          "neuralchat",
          "phi",
          "llama3",
          "gromenauer",
          "gemma2",
          "mistral-ins"
        ],
        "description": "Prompt Format. Specified in the HuggingFace model card"
      }
    }
  },
  "TTSFUNCTION": {
    "type": "select",
    "values": [
      "none",
      "melotts",
      "xtts-fastapi",
      "mimic3",
      "xvasynth",
      "azure",
      "11labs",
      "openai",
      "kokoro",
      "koboldcpp",
      "zonos_gradio"
    ],
    "description": "Text-to-Speech service options. Used to generate AI NPC voice.",
    "_title": "Text-to-Speech Service"
  },
  "TTS": {
    "_title": "Text-to-Speech Service",
    "MELOTTS": {
      "_title": "MeloTTS (Installed in DwemerDistro)",
      "endpoint": {
        "type": "url",
        "description": "Endpoint URL. Should be 'http://127.0.0.1:8084' if using default installation",
        "helpurl": "https://github.com/myshell-ai/MeloTTS"
      },
      "language": {
        "type": "select",
        "values": [
          "EN",
          "ES",
          "FR",
          "ZH",
          "JP",
          "KR"
        ],
        "description": "Language Model. Should be EN if using default installation"
      },
      "speed": {
        "type": "number",
        "description": "Speech Speed"
      },
      "voiceid": {
        "type": "string",
        "description": "Voice ID. Should be set automatically for most Vanilla Skyrim NPCs. Uses Skyrim VoiceType ID, e.g. femaleeventoned.<b> Click the help/doc link for full list of voiceids!</b>",
        "helpurl": "https://dwemerdynamics.hostwiki.io/en/TTS-Options#melotts-voice-ids"
      }
    },
    "XTTSFASTAPI": {
      "_title": "CHIM XTTS (Installed in DwemerDistro)",
      "endpoint": {
        "type": "url",
        "description": "Endpoint URL. Leave as default if you use CHIM XTTS.<br>You can run it on the cloud or use Mantella XTTS. Click the help link to learn more.",
        "helpurl": "https://dwemerdynamics.hostwiki.io/en/TTS-Options#chim-xtts"
      },
      "language": {
        "type": "select",
        "values": [
          "ar",
          "pt",
          "zh-cn",
          "cs",
          "nl",
          "en",
          "fr",
          "de",
          "it",
          "pl",
          "ru",
          "es",
          "tr",
          "ja",
          "ko",
          "hu",
          "hi"
        ],
        "description": "Language"
      },
      "voiceid": {
        "type": "string",
        "description": "Generated voice file name. Click the help link to go to XTTS management.",
        "helpurl": "/HerikaServer/ui/xtts_clone.php"
      },
      "voicelogic": {
        "type": "select",
        "values": [
          "voicetype",
          "name"
        ],
        "description": "Default profile only. Logic used for generating [TTS XTTSFASTAPI voiceid] <br> voicetype = NPC voicetype ID (femalenord) <br> name = NPC name (mjoll_the_lioness)",
        "scope": "global"
      }
    },
    "MIMIC3": {
      "_title": "MIMIC3 (Installed in DwemerDistro)",
      "URL": {
        "type": "url",
        "description": "MIMIC3 Service URL."
      },
      "voice": {
        "type": "string",
        "description": "Voice ID code"
      },
      "rate": {
        "type": "number",
        "description": "Voice speed"
      },
      "volume": {
        "type": "integer",
        "description": "Voice Volume"
      }
    },
    "XVASYNTH": {
      "_title": "xVASynth",
      "url": {
        "type": "url",
        "description": "xVASynth should be running on the same machine as DwemerDistro!<br>Must use your computers IP Address.<br>Can be found by running the command 'ipconfig' in your CMD prompt.<br>Example: http://your-local-ip:8008<br>Click the <b>help/doc</b> link for more info.",
        "helpurl": "https://dwemerdynamics.hostwiki.io/en/TTS-Options"
      },
      "base_lang": {
        "type": "string",
        "description": "Base language"
      },
      "modelType": {
        "type": "string",
        "description": "Model Type"
      },
      "version": {
        "type": "string",
        "description": "xVASynth version (e.g. 3.0 is default. Older models are 1.0 or 2.0)"
      },
      "game": {
        "type": "string",
        "description": "xVASynth gameID (e.g. skyrim)"
      },
      "model": {
        "type": "string",
        "description": "xVASynth voiceID (e.g. sk_femaleeventoned)"
      },
      "pace": {
        "type": "number",
        "description": "Pace"
      },
      "waveglowPath": {
        "type": "string",
        "description": "Wave Glow Path (relative)"
      },
      "vocoder": {
        "type": "string",
        "description": "Vocoder"
      },
      "distroname": {
        "type": "string",
        "description": "Leave as default!"
      }
    },
    "ZONOS_GRADIO": {
      "_title": "Zonos TTS",
      "endpoint": {
        "userlvl": "wip",
        "type": "url",
        "description": "Manual for Zonos <a href='https://dwemerdynamics.hostwiki.io/en/TTS-Options' target='_blank'>can be found here.</a> Endpoint URL. Can be ran on : <a href='https://cloud.vast.ai/?ref_id=177752&creator_id=177752&name=CHIM-Zonos%20(WORKING)' target='_blank'>Vast.ai</a>"
      },
      "language": {
        "userlvl": "wip",
        "type": "select",
        "values": [
          "af",
          "am",
          "an",
          "ar",
          "as",
          "az",
          "ba",
          "bg",
          "bn",
          "bpy",
          "bs",
          "ca",
          "cmn",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en-029",
          "en-gb",
          "en-gb-scotland",
          "en-gb-x-gbclan",
          "en-gb-x-gbcwmd",
          "en-gb-x-rp",
          "en-us",
          "eo",
          "es",
          "es-419",
          "et",
          "eu",
          "fa",
          "fa-latn",
          "fi",
          "fr-be",
          "fr-ch",
          "fr-fr",
          "ga",
          "gd",
          "gn",
          "grc",
          "gu",
          "hak",
          "hi",
          "hr",
          "ht",
          "hu",
          "hy",
          "hyw",
          "ia",
          "id",
          "is",
          "it",
          "ja",
          "jbo",
          "ka",
          "kk",
          "kl",
          "kn",
          "ko",
          "kok",
          "ku",
          "ky",
          "la",
          "lfn",
          "lt",
          "lv",
          "mi",
          "mk",
          "ml",
          "mr",
          "ms",
          "mt",
          "my",
          "nb",
          "nci",
          "ne",
          "nl",
          "om",
          "or",
          "pa",
          "pap",
          "pl",
          "pt",
          "pt-br",
          "py",
          "quc",
          "ro",
          "ru",
          "ru-lv",
          "sd",
          "shn",
          "si",
          "sk",
          "sl",
          "sq",
          "sr",
          "sv",
          "sw",
          "ta",
          "te",
          "tn",
          "tr",
          "tt",
          "ur",
          "uz",
          "vi",
          "vi-vn-x-central",
          "vi-vn-x-south",
          "yue"
        ],
        "description": "Language",
        "helpurl": "https://github.com/Zyphra/Zonos/blob/a09ff4fa50cfa66bf79986e19c191f85f5cb53e8/zonos/conditioning.py#L316"
      },
      "model": {
        "userlvl": "wip",
        "type": "select",
        "values": [
          "Zyphra/Zonos-v0.1-transformer",
          "Zyphra/Zonos-v0.1-hybrid"
        ],
        "description": "Default profile only. Model to use.",
        "scope": "global"
      },
      "dynamic_tones": {
        "userlvl": "wip",
        "type": "boolean",
        "description": "Default profile only. Enhance emotional quality by requesting values from the LLM. If false, emotions will be determined by the LLM-selected mood.",
        "scope": "global"
      },
      "voiceid": {
        "userlvl": "wip",
        "type": "string",
        "description": "Generated voice file name. Works the same as CHIM-XTTS voiceid and uses its voicelogic setting. Will only work with voices in your <a href='../data/voices' style='color: yellow;' target='_blank'>Voice Cache</a>."
      },
      "pitch_std": {
        "userlvl": "wip",
        "type": "number",
        "description": "Pitch standard deviation [0-300]"
      },
      "speaking_rate": {
        "userlvl": "wip",
        "type": "number",
        "description": "Speaking rate. Higher is faster. [5-30]"
      },
      "cfg_scale": {
        "userlvl": "wip",
        "type": "number",
        "description": "CFG scale. Controls how closely the audio matches the sample voice. Higher numbers will be a closer match. [1.1 - 5]"
      },
      "cached_voice_path": {
        "userlvl": "wip",
        "type": "string",
        "description": "Path to the sample audio stored in zonos. Leave as default; it is set automatically."
      }
    },
    "AZURE": {
      "_title": "Azure Text-To-Speech",
      "fixedMood": {
        "type": "string",
        "description": "Force mood (voice style)",
        "helpurl": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#use-speaking-styles-and-roles"
      },
      "region": {
        "type": "string",
        "description": "Region location of your API key"
      },
      "voice": {
        "type": "string",
        "description": "Voice",
        "helpurl": "https://speech.microsoft.com/portal/voicegallery"
      },
      "volume": {
        "type": "integer",
        "description": "Volume",
        "helpurl": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"
      },
      "rate": {
        "userlvl": "pro",
        "type": "number",
        "description": "Talk speed",
        "helpurl": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"
      },
      "countour": {
        "userlvl": "pro",
        "type": "string",
        "description": "Voice contour",
        "helpurl": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"
      },
      "validMoods": {
        "userlvl": "pro",
        "type": "selectmultiple",
        "values": [
          "angry",
          "chat",
          "cheerful",
          "customerservice",
          "empathetic",
          "excited",
          "friendly",
          "hopeful",
          "narration-professional",
          "newscast-casual",
          "newscast-formal",
          "sad",
          "shouting",
          "terrified",
          "unfriendly",
          "whispering",
          "default",
          "dazed"
        ],
        "description": "Allowed voice styles"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "Azure TTS API KEY",
        "code": "AZURE_API_KEY"
      }
    },
    "openai": {
      "_title": "OpenAI TTS",
      "endpoint": {
        "type": "url",
        "description": "Endpoint URL",
        "helpurl": "https://platform.openai.com/docs/guides/text-to-speech"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "API KEY"
      },
      "voice": {
        "type": "select",
        "values": [
          "alloy",
          "ash",
          "coral",
          "echo",
          "fable",
          "onyx",
          "nova",
          "sage",
          "shimmer"
        ],
        "description": "Voice ID",
        "helpurl": "https://platform.openai.com/docs/guides/text-to-speech"
      },
      "model_id": {
        "type": "select",
        "values": [
          "tts-1",
          "tts-1-hd",
          "gpt-4o-mini-tts"
        ],
        "description": "Model",
        "helpurl": "https://platform.openai.com/docs/guides/text-to-speech"
      },
      "instructions": {
        "type": "longstring",
        "description": "Control the voice of your generated audio with additional instructions. Does not work with tts-1 or tts-1-hd.",
        "helpurl": "https://platform.openai.com/docs/guides/text-to-speech"
      }
    },
    "ELEVEN_LABS": {
      "_title": "ElevenLabs Text-To-Speech",
      "voice_id": {
        "type": "string",
        "description": "Voice code",
        "helpurl": "https://elevenlabs.io/docs/api-reference/voices/get"
      },
      "optimize_streaming_latency": {
        "type": "string",
        "description": "Optimize Streaming Latency",
        "helpurl": "https://docs.elevenlabs.io/api-reference/text-to-speech"
      },
      "model_id": {
        "type": "string",
        "description": "Model ID",
        "helpurl": "https://beta.elevenlabs.io/speech-synthesis"
      },
      "stability": {
        "userlvl": "pro",
        "type": "number",
        "description": "Stability"
      },
      "similarity_boost": {
        "userlvl": "pro",
        "type": "number",
        "description": "Similarity_Boost"
      },
      "style": {
        "type": "number",
        "description": "Style"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "Eleven Labs API key.",
        "code": "11LABS_API_KEY"
      }
    },
    "GCP": {
      "_title": "Google Cloud Platform Text-To-Speech",
      "GCP_SA_FILEPATH": {
        "type": "string",
        "description": "Google Cloud Platform auth file. Should be placed in the data folder.",
        "helpurl": "https://google-auth.readthedocs.io/en/master/user-guide.html"
      },
      "voice_name": {
        "type": "string",
        "description": "Voice",
        "helpurl": "https://cloud.google.com/text-to-speech/docs/voices"
      },
      "voice_languageCode": {
        "type": "string",
        "description": "Language code",
        "helpurl": "https://developers.google.com/admin-sdk/directory/v1/languages"
      },
      "ssml_rate": {
        "type": "number",
        "description": "Rate"
      },
      "ssml_pitch": {
        "type": "string",
        "description": "Pitch"
      }
    },
    "CONVAI": {
      "_title": "CONVAI TTS",
      "endpoint": {
        "type": "url",
        "description": "Endpoint URL",
        "helpurl": "https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "API KEY"
      },
      "language": {
        "type": "select",
        "values": [
          "ar",
          "cmn-CN",
          "de-DE",
          "en-US",
          "es-ES",
          "es-MX",
          "es-US",
          "fr-FR",
          "hi-IN",
          "it-IT",
          "js-JP",
          "kk-KZ",
          "ko-KR",
          "nl-BE",
          "nl-NL",
          "pl-PL",
          "pt-BR",
          "pt-PT",
          "ru-RU",
          "sv-SE",
          "tr-TR",
          "vi-VN",
          "yue-HK",
          "zh-HK"
        ],
        "description": "Language",
        "helpurl": "https://platform.openai.com/docs/guides/text-to-speech"
      },
      "voiceid": {
        "type": "string",
        "description": "Voice id (check compatability with language)",
        "helpurl": "https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"
      },
      "description": "VoiceId",
      "helpurl": "https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"
    },
    "KOKORO": {
      "_title": "KOKORO 82M",
      "endpoint": {
        "type": "url",
        "description": "Endpoint URL",
        "helpurl": ""
      },
      "voiceid": {
        "type": "string",
        "description": "Voice id (check compatability with language)",
        "helpurl": ""
      },
      "speed": {
        "type": "number",
        "description": "Speed"
      }
    },
    "koboldcpp": {
      "_title": "KoboldCPP TTS",
      "endpoint": {
        "type": "url",
        "description": "Endpoint URL"
      },
      "voice": {
        "type": "string",
        "description": "Voice to use"
      }
    }
  },
  "TTSFUNCTION_PLAYER": {
    "type": "select",
    "userlvl": "basic",
    "scope": "global",
    "values": [
      "none",
      "melotts",
      "xtts-fastapi",
      "xvasynth",
      "mimic3",
      "azure",
      "11labs",
      "openai",
      "kokoro",
      "zonos_gradio"
    ],
    "description": "Text-to-Speech service options. Used to generate your voice.",
    "_title": "Player TTS"
  },
  "TTSFUNCTION_PLAYER_VOICE": {
    "type": "string",
    "userlvl": "basic",
    "scope": "global",
    "description": "VoiceID to use for the player character."
  },
  "TTSFUNCTION_PLAYER_LANGUAGE": {
    "type": "string",
    "userlvl": "basic",
    "scope": "global",
    "description": "Overrides the TTS language for the player character.<br/>If blank, the NPC's TTS language will be used."
  },
  "TRANSLATION_FUNCTION": {
    "type": "select",
    "userlvl": "basic",
    "values": [
      "none",
      "DeepL"
    ],
    "description": "Translate subtitles and/or audio into a different language.",
    "_title": "Translation Service"
  },
  "TRANSLATION": {
    "_title": "Translation Service",
    "settings": {
      "_title": "Translation Settings",
      "translate_audio": {
        "type": "boolean",
        "description": "This NPC's audio will be translated to the target language."
      },
      "translate_text": {
        "type": "boolean",
        "description": "This NPC's subtitles will be translated to the target language."
      },
      "save_translated_text": {
        "type": "boolean",
        "description": "Replaces the NPC's speech in the context history with the translation. Only used if translate_audio or translate_text is true."
      },
      "translate_player_audio": {
        "type": "boolean",
        "description": "When speaking to this NPC, Player TTS audio will be translated to the player target language."
      },
      "save_translated_player_text": {
        "type": "boolean",
        "description": "Replaces the player's input in the context history with the translation. Only used if translate_player_audio is true.<br/>Note: player subtitles are always displayed in their original language."
      }
    },
    "DeepL": {
      "_title": "DeepL",
      "source_language": {
        "type": "string",
        "description": "This NPC's source language to be translated from. This should be the language that the LLM responds with.<br/>May be left blank for auto-detection.",
        "helpurl": "https://developers.deepl.com/docs/getting-started/supported-languages#target-languages"
      },
      "target_language": {
        "type": "string",
        "description": "This NPC's target language to be translated into. <strong>Required.</strong>",
        "helpurl": "https://developers.deepl.com/docs/getting-started/supported-languages#target-languages"
      },
      "url": {
        "type": "url",
        "scope": "global",
        "description": "DeepL endpoint url. Default profile only.<br/>Free: https://api-free.deepl.com/v2/translate<br/>Pro: https://api.deepl.com/v2/translate"
      },
      "player_source_language": {
        "type": "string",
        "description": "Player's source language to be translated from. This should be the language you speak with STT or input by text.<br/>May be left blank for auto-detection.",
        "helpurl": "https://developers.deepl.com/docs/getting-started/supported-languages#target-languages"
      },
      "player_target_language": {
        "type": "string",
        "description": "Player's target language to be translated into.",
        "helpurl": "https://developers.deepl.com/docs/getting-started/supported-languages#target-languages"
      },
      "API_KEY": {
        "type": "apikey",
        "scope": "global",
        "description": "DeepL api key. Default profile only.<br/><strong>Required</strong> even when using the free version."
      }
    }
  },
  "PLAYER_REESPECH": {
    "type": "boolean",
    "description": "Use default diary connector AI to rewrite player speech Currently only triggers when strating speech with **",
    "scope": "global"
  },
  "STTFUNCTION": {
    "type": "select",
    "values": [
      "whisper",
      "localwhisper",
      "azure",
      "deepgram"
    ],
    "description": "Speech-to-Text service options. Translates your voice to text.",
    "_title": "Speech-to-Text Service",
    "scope": "global"
  },
  "STT": {
    "_title": "Speech-to-Text Service",
    "WHISPER": {
      "_title": "OpenAI's Whisper",
      "LANG": {
        "type": "string",
        "description": "Language to detect for STT."
      },
      "TRANSLATE": {
        "type": "boolean",
        "description": "Will try to translate to english."
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenAI API key. Same used for OpenAI/ChatGPT AI service.",
        "code": "OPENAI_API_KEY"
      }
    },
    "AZURE": {
      "_title": "Azure Speech-to-Text",
      "LANG": {
        "type": "string",
        "description": "Language to detect for STT."
      },
      "profanity": {
        "type": "select",
        "values": [
          "masked",
          "removed",
          "raw"
        ],
        "description": "Specifies how to handle profanity in recognition results. Accepted values are:<br>MASKED, which replaces profanity with asterisks.<br>REMOVED, which removes all profanity from the result.<br>RAW, which includes profanity in the result.",
        "helpurl": "https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-speech-to-text-short"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "Azure API key. Same used for Azure TTS Service.",
        "code": "AZURE_API_KEY"
      }
    },
    "LOCALWHISPER": {
      "_title": "Local Whisper (Installed in DwemerDistro)",
      "URL": {
        "type": "url",
        "description": "Local whisper endpoint. Leave as Default if you installed whisper through the Distro.",
        "helpurl": "https://www.nexusmods.com/skyrimspecialedition/mods/89931?tab=files"
      },
      "FORMFIELD": {
        "type": "select",
        "values": [
          "audio_file",
          "file"
        ],
        "description": "Form field name for audio file. Sometimes needed to change to file to use another shiper implementations"
      }
    },
    "DEEPGRAM": {
      "_title": "Deepgram's Whisper Speech-to-Text",
      "API_KEY": {
        "type": "apikey",
        "description": "Deepgram API key.",
        "code": "DEEPGRAM_API_KEY"
      },
      "LANG": {
        "type": "string",
        "description": "Language"
      },
      "MODEL": {
        "type": "select",
        "values": [
          "nova-2",
          "whisper-medium",
          "enhanced",
          "nova",
          "base"
        ],
        "description": "Model to use"
      }
    }
  },
  "ITTFUNCTION": {
    "type": "select",
    "values": [
      "openai",
      "google_openai",
      "llamacpp"
    ],
    "description": "Image recognition aka Soulgaze spell. OpenAI also works as a connector to OpenRouter!<br><br><strong>Must be configured in default profile!</strong>",
    "_title": "Soulgaze (ITT)",
    "scope": "global",
    "quality": {
      "type": "int",
      "description": "Only when using Soulgaze HD. Compression quality from 0 (lower and unusable) to 100 (near no compression). More quality means higher file size, ergo more tokens.",
      "scope": "global"
    }
  },
  "ITT": {
    "openai": {
      "_title": "OpenAI/OpenRouter",
      "url": {
        "type": "url",
        "description": "OpenAI API or OpenRouter endpoint. Use this for OpenRouter (https://openrouter.ai/api/v1/chat/completions)",
        "scope": "global"
      },
      "model": {
        "type": "string",
        "description": "Model to use",
        "helpurl": "https://platform.openai.com/docs/models/",
        "scope": "global"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate",
        "scope": "global"
      },
      "detail": {
        "type": "select",
        "values": [
          "low",
          "high"
        ],
        "description": "Low or high fidelity image understanding",
        "helpurl": "https://platform.openai.com/docs/guides/vision?lang=curl",
        "scope": "global"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenAI API key",
        "code": "OPENAI_API_KEY",
        "helpurl": "https://platform.openai.com/account/api-keys",
        "scope": "global"
      },
      "AI_VISION_PROMPT": {
        "type": "longstring",
        "description": "Prompt to send to the OpenAI vision model.",
        "scope": "global"
      },
      "AI_PROMPT": {
        "type": "longstring",
        "description": "Prompt for the AI NPC to follow when describing the scene."
      }
    },
    "google_openai": {
      "_title": "Google OpenAI API",
      "url": {
        "type": "url",
        "description": "Google OpenAI API.",
        "scope": "global"
      },
      "model": {
        "type": "string",
        "description": "Model to use",
        "helpurl": "https://ai.google.dev/gemini-api/docs/models/gemini",
        "scope": "global"
      },
      "max_tokens": {
        "type": "integer",
        "description": "Maximum tokens to generate",
        "scope": "global"
      },
      "detail": {
        "type": "select",
        "values": [
          "low",
          "high"
        ],
        "description": "Low or high fidelity image understanding",
        "helpurl": "https://platform.openai.com/docs/guides/vision?lang=curl",
        "scope": "global"
      },
      "API_KEY": {
        "type": "apikey",
        "description": "OpenAI API key",
        "code": "OPENAI_API_KEY",
        "helpurl": "https://aistudio.google.com/apikey",
        "scope": "global"
      },
      "AI_VISION_PROMPT": {
        "type": "longstring",
        "description": "Prompt to send to the OpenAI vision model.",
        "scope": "global"
      },
      "AI_PROMPT": {
        "type": "longstring",
        "description": "Prompt for the AI NPC to follow when describing the scene."
      }
    },
    "llamacpp": {
      "_title": "LLama Server (Installed in DwemerDistro)",
      "URL": {
        "type": "url",
        "description": "URL of the llama.cpp server",
        "helpurl": "https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md",
        "scope": "global"
      },
      "AI_VISION_PROMPT": {
        "type": "longstring",
        "description": "Prompt to send to the llama vision model.",
        "scope": "global"
      },
      "AI_PROMPT": {
        "type": "longstring",
        "description": "Prompt for the AI NPC to follow when describing the scene."
      }
    }
  },
  "FEATURES": {
    "_title": "Memory Configuration",
    "MEMORY_EMBEDDING": {
      "_title": "Memory Settings",
      "ENABLED": {
        "type": "boolean",
        "description": "<Strong>Make sure CONNECTORS_DIARY is setup!</strong> Enable long term memory. It will provide the most relevant memory with every AI response to be used as context."
      },
      "TXTAI_URL": {
        "type": "url",
        "description": "TXT2VEC from DwemerDistro. Make sure its set to http://127.0.0.1:8082"
      },
      "USE_TEXT2VEC": {
        "type": "boolean",
        "description": "Use TXT2VEC to create embeddings for memories. These are more accurate than keywords."
      },
      "MEMORY_TIME_DELAY": {
        "type": "integer",
        "description": "Time in minutes to delay before using a memory in a prompt. Used to avoid pushing recent dialogues as memories."
      },
      "MEMORY_CONTEXT_SIZE": {
        "type": "integer",
        "description": "The amount of the most relevant memory records that will be injected into the prompt."
      },
      "AUTO_CREATE_SUMMARYS": {
        "type": "boolean",
        "description": "Will combine individual memory logs into larger ones. Is more accurate for memory recollection but will use up more tokens. If using koboldcpp, use the multiuser mode to avoid locking."
      },
      "AUTO_CREATE_SUMMARY_INTERVAL": {
        "type": "integer",
        "description": "Time frame used to pack summary data. 10 = 13 in-game hours | 5 = 7.5 in-game hours etc"
      },
      "MEMORY_BIAS_A": {
        "type": "number",
        "description": "From 0 (never) to 100 (always). Minimal distance to offer memory."
      },
      "MEMORY_BIAS_B": {
        "type": "number",
        "description": "From 0 (never) to 100 (always). Minimal distance to offer and endorse memory."
      }
    },
    "MISC": {
      "_title": "Experimental Options (Use at your own risk!)",
      "ADD_TIME_MARKS": {
        "userlvl": "wip",
        "type": "boolean",
        "description": "Add timestamps to the context logs. Helps with memory recollection."
      },
      "ITT_QUALITY": {
        "userlvl": "wip",
        "type": "integer",
        "description": "Only for Soulgaze HD. Compression quality can be set from 0 (lower and unusable) to 100 (near no compression). More quality means higher file size, ergo more tokens.",
        "scope": "global"
      },
      "TTS_RANDOM_PITCH": {
        "type": "boolean",
        "userlvl": "wip",
        "description": "WIP DO NOT USE! Adjusting the pitch when generating the voice for this actor will add variation, so actors using the same voice sound slightly distinct."
      },
      "LIFE_LINK_PLUGIN": {
        "type": "boolean",
        "userlvl": "wip",
        "description": "WIP. Is disabled currently, do not enable is a work in progress."
      }
    }
  }
}